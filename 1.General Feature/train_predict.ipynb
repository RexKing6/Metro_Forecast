{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一部分的做法是将序列直接看成普通特征，用sklearn中的各种回归试试效果，在最后还试了一个两层的神经网络，效果还是没普通的线性回归好。最终交了线性回归的预测结果，成绩很差，比直接交28好还差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_day = 28\n",
    "metro_file = pd.read_csv('./Metro_testA/testA_record_2019-01-'+str(pred_day).zfill(2)+'.csv')\n",
    "metro_file.time = pd.to_datetime(metro_file.time)\n",
    "start_time = '2019-01-'+str(pred_day)+' 00:00:00'\n",
    "start_time = pd.to_datetime(start_time)\n",
    "end_time = '2019-01-'+str(pred_day)+' 00:10:00'\n",
    "end_time = pd.to_datetime(end_time)\n",
    "tenmin_delta = end_time - start_time\n",
    "metro_dfs = []\n",
    "for k in range(81):\n",
    "    metro_dfs.append(pd.DataFrame(np.zeros((144, 11))))\n",
    "for j in range(144):\n",
    "    metro_tmp = metro_file[(metro_file.time>=start_time) & (metro_file.time<end_time)].groupby(['stationID', 'status', 'payType']).count()\n",
    "    for k in range(81):\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 0] = metro_tmp.loc[k, 1].time.sum()\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 0] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 1] = metro_tmp.loc[k, 1, 0].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 1] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 2] = metro_tmp.loc[k, 1, 1].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 2] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 3] = metro_tmp.loc[k, 1, 2].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 3] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 4] = metro_tmp.loc[k, 1, 3].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 4] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 5] = metro_tmp.loc[k, 0].time.sum()\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 5] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 6] = metro_tmp.loc[k, 0, 0].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 6] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 7] = metro_tmp.loc[k, 0, 1].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 7] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 8] = metro_tmp.loc[k, 0, 2].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 8] = 0\n",
    "        try:\n",
    "            metro_dfs[k].loc[j, 9] = metro_tmp.loc[k, 0, 3].time\n",
    "        except:\n",
    "            metro_dfs[k].loc[j, 9] = 0\n",
    "        if start_time.weekday()<=4:\n",
    "            metro_dfs[k].loc[j, 10] = 0\n",
    "        else:\n",
    "            metro_dfs[k].loc[j, 10] = 1\n",
    "    start_time = end_time\n",
    "    end_time += tenmin_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(81):\n",
    "    metro_dfs[i].rename(columns={0:'in_num', 1:'in_paytype_0', 2:'in_paytype_1', 3:'in_paytype_2', 4:'in_paytype_3', \n",
    "                                 5:'out_num', 6:'out_paytype_0', 7:'out_paytype_1', 8:'out_paytype_2', 9:'out_paytype_3',\n",
    "                                 10:'weekend'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_day = 28\n",
    "eval_features = np.zeros((81, 2, 1, 144 * 6 + 2))\n",
    "all_min_max = np.load('./Metro_data/all_min_max.npy').item()\n",
    "for istation in range(81):\n",
    "    if istation != 54:\n",
    "        istation_min_max = all_min_max['station-'+str(istation).zfill(2)]\n",
    "        metro_dfs[istation].iloc[:, [0,5,1,2,3,4,6,7,8,9]] = (metro_dfs[istation].iloc[:, [0,5,1,2,3,4,6,7,8,9]] - np.array([istation_min_max['in']['in_num_min'],\n",
    "                                                       istation_min_max['in']['out_num_min'],\n",
    "                                                       istation_min_max['in']['in_paytype_0_min'],\n",
    "                                                       istation_min_max['in']['in_paytype_1_min'],\n",
    "                                                       istation_min_max['in']['in_paytype_2_min'],\n",
    "                                                       istation_min_max['in']['in_paytype_3_min'],\n",
    "                                                       istation_min_max['out']['out_paytype_0_min'],\n",
    "                                                       istation_min_max['out']['out_paytype_1_min'],\n",
    "                                                       istation_min_max['out']['out_paytype_2_min'],\n",
    "                                                       istation_min_max['out']['out_paytype_3_min'],\n",
    "                                                      ]))/(np.array([istation_min_max['in']['in_num_max'],\n",
    "                                                                    istation_min_max['in']['out_num_max'],\n",
    "                                                                    istation_min_max['in']['in_paytype_0_max'],\n",
    "                                                                    istation_min_max['in']['in_paytype_1_max'],\n",
    "                                                                    istation_min_max['in']['in_paytype_2_max'],\n",
    "                                                                    istation_min_max['in']['in_paytype_3_max'],\n",
    "                                                                    istation_min_max['out']['out_paytype_0_max'],\n",
    "                                                                    istation_min_max['out']['out_paytype_1_max'],\n",
    "                                                                    istation_min_max['out']['out_paytype_2_max'],\n",
    "                                                                    istation_min_max['out']['out_paytype_3_max'],\n",
    "                                     ])-np.array([istation_min_max['in']['in_num_min'],\n",
    "                                                  istation_min_max['in']['out_num_min'],\n",
    "                                                  istation_min_max['in']['in_paytype_0_min'],\n",
    "                                                  istation_min_max['in']['in_paytype_1_min'],\n",
    "                                                  istation_min_max['in']['in_paytype_2_min'],\n",
    "                                                  istation_min_max['in']['in_paytype_3_min'],\n",
    "                                                  istation_min_max['out']['out_paytype_0_min'],\n",
    "                                                  istation_min_max['out']['out_paytype_1_min'],\n",
    "                                                  istation_min_max['out']['out_paytype_2_min'],\n",
    "                                                  istation_min_max['out']['out_paytype_3_min'],\n",
    "                                                 ]))\n",
    "        if pd.to_datetime('2019-01-'+str(pred_day+1).zfill(2)).weekday()<=4:\n",
    "            weekend = np.array((metro_dfs[0].iloc[2,-1], 0))\n",
    "        else:\n",
    "            weekend = np.array((metro_dfs[0].iloc[2,-1], 1))\n",
    "        station_feature = metro_dfs[istation]\n",
    "        for jinout in range(2):\n",
    "            if jinout == 0:\n",
    "                eval_features[istation, jinout, 0, :] = np.hstack((station_feature.iloc[:,[0,5,1,2,3,4]].values.reshape(-1),weekend))\n",
    "            else:\n",
    "                eval_features[istation, jinout, 0, :] = np.hstack((station_feature.iloc[:,[0,5,6,7,8,9]].values.reshape(-1),weekend))\n",
    "np.save('eval_feature.npy', eval_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = np.load('train_feature.npy')\n",
    "train_label = np.load('train_label.npy')\n",
    "test_feature = np.load('test_feature.npy')\n",
    "test_label = np.load('test_label.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 浅层回归方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train_feature, train_label, test_feature, test_label):\n",
    "    model.fit(train_feature, train_label)\n",
    "    train_pred_label = model.predict(train_feature)\n",
    "    test_pred_label = model.predict(test_feature)\n",
    "    train_loss = mean_squared_error(train_pred_label, train_label)\n",
    "    test_loss = mean_squared_error(test_pred_label, test_label)\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pred_model(model, train_feature, train_label, test_feature, test_label, eval_feature):\n",
    "    model.fit(train_feature, train_label)\n",
    "    train_pred_label = model.predict(train_feature)\n",
    "    test_pred_label = model.predict(test_feature)\n",
    "    train_loss = mean_squared_error(train_pred_label, train_label)\n",
    "    test_loss = mean_squared_error(test_pred_label, test_label)\n",
    "    eval_pred_label = model.predict(eval_feature)\n",
    "    return eval_pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注释行左边为训练总MSE，右边为测试总MSE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import tree\n",
    "# model = tree.DecisionTreeRegressor()\n",
    "# # 0.0 0.627775450234844\n",
    "\n",
    "from sklearn import linear_model\n",
    "model = linear_model.LinearRegression()\n",
    "# 4.908710878115789e-29 0.30115703199174515\n",
    "\n",
    "# from sklearn import neighbors\n",
    "# model = neighbors.KNeighborsRegressor(n_neighbors=2)\n",
    "# # 0.08803345179195304 0.34083946240049395\n",
    "\n",
    "# from sklearn import ensemble\n",
    "# model = ensemble.RandomForestRegressor(n_estimators=20)\n",
    "# # 0.07614751868807886 0.5845056823843853\n",
    "\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# model = BaggingRegressor()\n",
    "# # 0.08886360769056594 0.6181388945928975\n",
    "\n",
    "# from sklearn.tree import ExtraTreeRegressor\n",
    "# model = ExtraTreeRegressor()\n",
    "# # 0.0 0.42660316809456345\n",
    "\n",
    "all_train_loss = 0\n",
    "all_test_loss = 0\n",
    "for istation in range(81):\n",
    "    for jinout in range(2):\n",
    "        model = linear_model.LinearRegression()\n",
    "        train_loss, test_loss = fit_model(model, train_feature[istation][jinout], train_label[istation][jinout], test_feature[istation][jinout], test_label[istation][jinout])\n",
    "        all_train_loss += train_loss\n",
    "        all_test_loss += test_loss\n",
    "print(all_train_loss, all_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_label = fit_pred_model(model, train_feature[0][0], train_label[0][0], \n",
    "                            test_feature[0][0], test_label[0][0], eval_features[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两层神经网络回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = torch.from_numpy(train_feature)\n",
    "train_feature = train_feature.float()\n",
    "train_feature = Variable(train_feature)\n",
    "train_feature = train_feature.cuda()\n",
    "\n",
    "train_label = torch.from_numpy(train_label)\n",
    "train_label = train_label.float()\n",
    "train_label = Variable(train_label)\n",
    "train_label = train_label.cuda()\n",
    "\n",
    "test_feature = torch.from_numpy(test_feature)\n",
    "test_feature = test_feature.float()\n",
    "test_feature = Variable(test_feature)\n",
    "test_feature = test_feature.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=144):\n",
    "        super(FCNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FCNet(input_size = train_feature.shape[-1], hidden_size = 144 * 3, output_size=144)\n",
    "net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "net.cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.07769668544656838 0.5089264005598018\n",
    "train_loss = 0\n",
    "test_loss = 0\n",
    "for istation in range(81):\n",
    "    for jinout in range(2):\n",
    "        net = FCNet(input_size = train_feature.shape[-1], hidden_size = 144 * 3, output_size=144)\n",
    "        net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "        net.cuda()\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "        for epoch in range(128):\n",
    "            net.train()\n",
    "            out = net(train_feature[istation][jinout])\n",
    "            loss = criterion(out, train_label[istation][jinout])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            net.eval()\n",
    "            pred_label = net(test_feature[istation][jinout])\n",
    "            pred_label = pred_label.data.cpu().numpy()\n",
    "            mse = np.mean((pred_label - test_label[istation][jinout]) ** 2)\n",
    "        train_loss += loss.item()\n",
    "        test_loss += mse\n",
    "print(train_loss, test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测\n",
    "比较之后，最终用线性回归进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((11664, 2))\n",
    "for istaiton in range(81):\n",
    "    for jinout in range(2):\n",
    "        model = linear_model.LinearRegression()\n",
    "        eval_label = fit_pred_model(model, train_feature[istation][jinout], train_label[istation][jinout], test_feature[istation][jinout], test_label[istation][jinout], eval_features[istaiton][jinout])\n",
    "        if jinout == 0:\n",
    "            ij_min = all_min_max['station-'+str(istaiton).zfill(2)]['in']['label_min']\n",
    "            ij_max = all_min_max['station-'+str(istaiton).zfill(2)]['in']['label_max']\n",
    "        else:\n",
    "            ij_min = all_min_max['station-'+str(istaiton).zfill(2)]['out']['label_min']\n",
    "            ij_max = all_min_max['station-'+str(istaiton).zfill(2)]['out']['label_max']\n",
    "        eval_label = eval_label * (ij_max - ij_min) + ij_min\n",
    "        eval_label = pd.DataFrame(eval_label.transpose())\n",
    "        eval_label[eval_label.iloc[:,0]<0] = 0\n",
    "        eval_label = np.array(eval_label).round().reshape(-1)\n",
    "        result[istaiton*144:(istaiton+1)*144, jinout] = eval_label\n",
    "result = pd.DataFrame(result)\n",
    "result.to_csv('pred.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
